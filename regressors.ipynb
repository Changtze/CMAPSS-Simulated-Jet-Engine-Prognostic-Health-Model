{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter as svg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.random.seed(111)  # reproducibility",
   "id": "6f1159f18b294b0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:43.617795Z",
     "start_time": "2024-07-29T16:55:43.612077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading file paths\n",
    "\n",
    "#train_path = 'D:/DataScience/CMAPSS/Data/train_FD00X.txt'\n",
    "#test_path = 'D:/DataScience/CMAPSS/Data/test_FD00X.txt'\n",
    "#RUL_path = 'D:/DataScience/CMAPSS/Data/RUL_FD00X.txt'\n",
    "\n",
    "train_path = f'E:/CMAPSS/data/train_FD00X.txt'\n",
    "test_path = f'E:/CMAPSS/data/test_FD00X.txt'\n",
    "RUL_path = f'E:/CMAPSS/data/RUL_FD00X.txt'\n",
    "\n",
    "\n",
    "labels = ['unit', 'cycles', 'opMode1', 'opMode2', 'opMode3'] + [f'sensor{i}' for i in range(1, 22)]  # column headers, see readme file"
   ],
   "id": "23af55bc433fc6f",
   "outputs": [],
   "execution_count": 278
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:43.952551Z",
     "start_time": "2024-07-29T16:55:43.945930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to load data and drop the columns specified by cols_to_drop, and add an RUL column for each unit\n",
    "def load_data(filepath, rul=False):\n",
    "    data = []\n",
    "    # Creating lists which hold dataframes for each test trajectory\n",
    "    if not rul:\n",
    "        for i in range(1, 5):\n",
    "            data.append(pd.read_csv(filepath.replace('X', str(i)),\n",
    "                                    names=labels, delimiter='\\s+',\n",
    "                                    ))\n",
    "        return data\n",
    "    else:\n",
    "        for i in range(1, 5):\n",
    "            data.append(pd.read_csv(filepath.replace('X', str(i)),\n",
    "                                    delimiter='\\s+', header=None,\n",
    "                                    ))\n",
    "\n",
    "        return data  # a list\n",
    "\n",
    "\n",
    "def prepare_data(train_data: pd.DataFrame):\n",
    "    # Adds an RUL column for training\n",
    "    ### TRAINING DATAFRAMES ###\n",
    "\n",
    "    rul = pd.DataFrame(train_data.groupby('unit')['cycles'].max()).reset_index()\n",
    "    rul.columns = ['unit', 'max']\n",
    "\n",
    "    train_data = train_data.merge(rul, on=['unit'], how='left')\n",
    "\n",
    "    train_data['RUL'] = train_data['max'] - train_data['cycles']\n",
    "    train_data.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    return train_data"
   ],
   "id": "c89ae6bad19dc45e",
   "outputs": [],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:47.422604Z",
     "start_time": "2024-07-29T16:55:44.869425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialising data\n",
    "train_data, test_data, RUL_data = load_data(train_path), load_data(test_path), load_data(RUL_path, True)"
   ],
   "id": "b6a71e24f47dcad4",
   "outputs": [],
   "execution_count": 280
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:47.472482Z",
     "start_time": "2024-07-29T16:55:47.424375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding RUL columns \n",
    "for i in range(len(train_data)):\n",
    "    train_data[i] = prepare_data(train_data[i])"
   ],
   "id": "63ab50f2b581c078",
   "outputs": [],
   "execution_count": 281
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data[0]",
   "id": "48d618a3d1b22fc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can observe, generally, the trend between the sensor readings and the RUL. Although the data is very noisy, the engines are all of the same make but only subject to different arbitrary conditions of wear and tear. We can go through a smaller subset of engine units, say 10 out of the 100. \n",
   "id": "6f4811988cb64397"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data[0].describe()",
   "id": "6ba928d19279a212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Columns with a very low standard deviation can be ignored as it shows the values are roughly constant. Constant values do not have much bearing on machine learning methods.",
   "id": "1acbd46f87839286"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_sensor_reading(df, sensor_no):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i in df['unit'].unique():\n",
    "        if (i % 10 == 0):  # 10 engines only (100 in total)\n",
    "            plt.plot('RUL', sensor_no, data=df[df['unit'] == i].rolling(10).mean())\n",
    "    plt.xticks(np.arange(0, 300, 25))\n",
    "    plt.ylabel(f'Sensor {sensor_no} reading')\n",
    "    plt.xlabel('Remaining useful life (RUL)')\n",
    "    plt.show()"
   ],
   "id": "ee813eb992ddb258",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:52.012624Z",
     "start_time": "2024-07-29T16:55:51.985940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trajectories FD001 and FD003 both have redundant readings which can be dropped as they are constant or rarely change. FD004 and FD002 both have a redundant sensor 16.\n",
    "cols_to_drop = ['opMode3', 'sensor1', 'sensor5',\n",
    "                'sensor6', 'sensor10', 'sensor16',\n",
    "                'sensor18', 'sensor19', 'sensor17']\n",
    "\n",
    "train_data[0].drop(columns=cols_to_drop, inplace=True)\n",
    "train_data[2].drop(columns=cols_to_drop, inplace=True)\n",
    "test_data[0].drop(columns=cols_to_drop, inplace=True)\n",
    "test_data[2].drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "train_data[1].drop(columns=['sensor16'], inplace=True)\n",
    "train_data[3].drop(columns=['sensor16'], inplace=True)\n"
   ],
   "id": "8308b0939a1a6625",
   "outputs": [],
   "execution_count": 282
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.heatmap(train_data[0].corr(), annot=True, cmap='BuPu', linewidths=0.2)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 20)\n",
    "plt.show()"
   ],
   "id": "4a54d19645c0b34a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:54.031535Z",
     "start_time": "2024-07-29T16:55:54.020969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing properties with weak correlation and high inter-correlation\n",
    "# sensor 14 and has aa very high correlation with sensor 9, we can remove sensor 14 to reduce multicollinearity\n",
    "train_data[0].drop(columns=['opMode1', 'opMode2', 'sensor14'], inplace=True)\n",
    "test_data[0].drop(columns=['opMode1', 'opMode2', 'sensor14'], inplace=True)\n",
    "train_data[2].drop(columns=['opMode1', 'opMode2', 'sensor14'], inplace=True)\n",
    "test_data[2].drop(columns=['opMode1', 'opMode2', 'sensor14'], inplace=True)"
   ],
   "id": "bf0439e9e4df66bf",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:55:54.613808Z",
     "start_time": "2024-07-29T16:55:54.591959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Min-max scaling the data, except [cycles, RUL]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "train_data[0].iloc[:, 2:-1] = scaler.fit_transform(train_data[0].iloc[:, 2:-1])\n",
    "test_data[0].iloc[:, 2:] = scaler.transform(test_data[0].iloc[:, 2:])\n",
    "\n",
    "train_data[2].iloc[:, 2:-1] = scaler.fit_transform(train_data[2].iloc[:, 2:-1])\n",
    "test_data[2].iloc[:, 2:] = scaler.transform(test_data[2].iloc[:, 2:])\n"
   ],
   "id": "1e5f5630cf8572b6",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating a training sequence\n",
    "def create_training_sequence(df, seq_length, seq_cols):\n",
    "    \n",
    "    \"\"\"function to prepare training data into (samples, time steps, features)\n",
    "    df = training dataframe\n",
    "    seq_length = look-back period\n",
    "    seq_cols = feature columns\"\"\"\n",
    "\n",
    "    data_array = df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "\n",
    "    lstm_array = []\n",
    "\n",
    "    for start, stop in zip(range(0, num_elements - seq_length + 1), range(seq_length, num_elements + 1)):\n",
    "        lstm_array.append(data_array[start:stop, :])\n",
    "\n",
    "    return np.array(lstm_array)\n",
    "\n",
    "def create_target_sequence(df, seq_length, label):\n",
    "    data_array = df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length - 1:num_elements + 1]\n",
    "\n",
    "\n",
    "def create_training_batch(df, seq_length, columns):\n",
    "    \"\"\"Since the test data is stopped some arbitrary time before failure,\n",
    "       the number of engine cycles won't necessarily be longer than a given window length,\n",
    "       so we generate testing sequences which meet the sequence_length \n",
    "       \"\"\"\n",
    "    x = np.concatenate(\n",
    "        list(list(create_training_sequence(df[df['unit'] == i], seq_length, columns)) for i in df['unit'].unique()))\n",
    "    y = np.concatenate(\n",
    "        list(list(create_target_sequence(df[df['unit'] == i], seq_length, 'RUL')) for i in df['unit'].unique()))\n",
    "    return x, y\n"
   ],
   "id": "8ac362e993dfe4a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "FD_columns = [[column for column in df if column != 'RUL'] for df in train_data]",
   "id": "b549bf6d2432bf93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sequence_length = 15\n",
    "trajectory = 0  # see readme file\n",
    "batch_size = 200"
   ],
   "id": "98040b8fbdad1f3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FD001_train = train_data[trajectory]\n",
    "FD001_test = test_data[trajectory]\n",
    "FD001_truth = RUL_data[trajectory]"
   ],
   "id": "ee8d5524e397eeb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a, b = create_training_batch(FD001_train, sequence_length, FD_columns[trajectory])",
   "id": "b7f900b7afc12e6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_count_r = a.shape[2]  # feature count for SVM and random forests\n",
    "out_dim = 1  # output dimension (1 RUL value)"
   ],
   "id": "ce34f6cd55228479",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_train, x_val, y_train, y_val = train_test_split(a, b, test_size=0.3, random_state=42)",
   "id": "d768a6a9994f4240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Using the ground truth labels to create an RUL column in the test data\n",
    "rul = pd.DataFrame(FD001_test.groupby('unit')['cycles'].max()).reset_index()\n",
    "rul.columns = ['unit', 'max']\n",
    "FD001_truth.columns = ['rulTruth']\n",
    "FD001_truth['unit'] = np.arange(1, len(rul) + 1, 1)  # 100 units\n",
    "FD001_truth['startLife'] = rul['max'] + FD001_truth['rulTruth']  # \n",
    "FD001_truth.drop(columns=['rulTruth'], inplace=True)"
   ],
   "id": "ae2197e4781e311b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FD001_test = FD001_test.merge(FD001_truth, on=['unit'], how='left')\n",
    "FD001_test['RUL'] = FD001_test['startLife'] - FD001_test['cycles']\n",
    "FD001_test.drop('startLife', axis=1, inplace=True)"
   ],
   "id": "c876aef74c966efa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_cols = list(FD001_test.columns[:-1])\n",
    "x_test = create_training_sequence(FD001_test, sequence_length, test_cols)"
   ],
   "id": "4ae2da8f7b64f705",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model performance functions\n",
   "id": "f15318db2835a622"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluation_metrics(ground_truth, prediction):\n",
    "    print(f\"Mean squared error: {mean_squared_error(ground_truth, prediction)}\")\n",
    "    print(f\"Root mean squared error: {root_mean_squared_error(ground_truth, prediction)}\")\n",
    "    print(f\"R2 score: {r2_score(ground_truth, prediction)}\")\n",
    "    print(f\"Mean absolute error: {mean_absolute_error(ground_truth, prediction)}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def loss_graphs(model):\n",
    "    # expects a tuple of training and validation losses\n",
    "    e = range(1, len(model[0]) + 1)  # the lists in the tuple are of equal length, can be model[1]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(e, model[0], 'b', label='Training loss')\n",
    "    plt.plot(e, model[1], 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "f36fcdd5a2d20dd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random forests",
   "id": "41ce9d328dd84485"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=90, n_jobs=-1, max_features=13, max_depth=10, random_state=42)\n",
    "\n",
    "# Reshaping 3D tensors for random forest compatibility\n",
    "x_train_reshaped = x_train.reshape(x_train.shape[0], sequence_length * feature_count_r)\n",
    "x_val_reshaped = x_val.reshape(x_val.shape[0], sequence_length * feature_count_r)\n",
    "x_test_reshaped = x_test.reshape(x_test.shape[0], sequence_length * feature_count_r)\n",
    "start_idx = 2000\n",
    "end_idx = 2900\n",
    "\n",
    "truncated_ground_truth = FD001_test['RUL'][(sequence_length-1):].reset_index(drop=True)\n",
    "truncated_subset = truncated_ground_truth[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "rf.fit(x_train_reshaped, y_train)\n",
    "rf_val_predictions = rf.predict(x_val_reshaped)\n",
    "print('Validation metrics:')\n",
    "evaluation_metrics(y_val, rf_val_predictions)\n",
    "\n",
    "print('\\nTest data metrics:')\n",
    "rf_test_predictions = rf.predict(x_test_reshaped)\n",
    "evaluation_metrics(truncated_ground_truth, rf_test_predictions)\n"
   ],
   "id": "fbdd6b12b2bd9f40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estim = RandomForestRegressor()\n",
    "\n",
    "# performing grid search for RF regressor\n",
    "param_grid = {\n",
    "    'n_estimators': [70, 90, 120],\n",
    "    'max_depth': [7, 8, 9],\n",
    "    'max_features': [8, 9, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estim, param_grid, n_jobs=-1, cv=3)\n",
    "grid.fit(x_train_reshaped, y_train)\n",
    "print(grid.best_score_, grid.best_params_)\n"
   ],
   "id": "369d367285ac3cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict and train using optimised model\n",
    "rf_final = RandomForestRegressor(n_estimators=70, max_depth=9, max_features=10, random_state=42)\n",
    "rf_final.fit(x_train_reshaped, y_train)\n",
    "\n",
    "print('Train data metrics:')\n",
    "final_train_predictions = rf_final.predict(x_train_reshaped)\n",
    "evaluation_metrics(y_train, final_train_predictions)\n",
    "\n",
    "print('\\nValidation data metrics:')\n",
    "final_val_predictions = rf_final.predict(x_val_reshaped)\n",
    "evaluation_metrics(y_val, final_val_predictions)\n",
    "\n",
    "print('\\nTest data metrics:')\n",
    "final_test_predictions = rf_final.predict(x_test_reshaped)\n",
    "evaluation_metrics(truncated_ground_truth, final_test_predictions)\n"
   ],
   "id": "f21cbb9022569eb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVM",
   "id": "5adfc00c32291841"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_regressor = SVR(kernel='rbf')\n",
    "svr_regressor.fit(x_train_reshaped, y_train) "
   ],
   "id": "b90d419ae8baa2e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_svr_train = svr_regressor.predict(x_train_reshaped)\n",
    "y_svr_test = svr_regressor.predict(x_test_reshaped)\n",
    "y_svr_val = svr_regressor.predict(x_val_reshaped)"
   ],
   "id": "31d9c63a382939c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Training data performance: ')\n",
    "evaluation_metrics(y_train, y_svr_train)\n",
    "print('\\nTest data performance: ')\n",
    "evaluation_metrics(truncated_ground_truth, y_svr_test)\n",
    "print('\\nValidation data performance: ')\n",
    "evaluation_metrics(y_val, y_svr_val)"
   ],
   "id": "663d5f4913627d8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
